\section{Introduction}\label{sec:intro}
Throughout this paper, $\KK$ is a field of characteristic zero with algebraic closure
$\KKbar$, $(X_1, \ldots, X_n)$ is a set of $n$ variables, and
$\KK[X_1,\dots,X_n]$ is the multivariate polynomial ring in $n$ variables with
coefficients in $\KK$. With this setup, let $\mF=[f_{i,j}] \in
\KK[X_1,\dots,X_n]^{p \times q}$ be a polynomial matrix, with $p \leq q$ and
$\mG = (g_1, \ldots, g_s)$ in $\KK[X_1, \ldots, X_n]$.

The central question which interests us here is to describe the set
$$\VpFG{p}{\mF}{\mG} = \{\bx \in \KKbar{}^n \mid
\mathrm{rank}(\mF({\bx})) < p \text{~and~} g_1(\bx)=\cdots=g_s(\bx)=0
\}$$

For any matrix $\mF$ over a ring $R$, and for any integer $r$,
$M_r(\mF)$ will denote the set of $r$-minors of $\mF$. For any subset $I$ in
$\KK[X_1,\dots,X_n]$, $V(I)$ will denote the zero-set of $I$ in
$\KKbar{}^n$, and for a matrix $\mF$ with entries in
$\KK[X_1,\dots,X_n]$, we will write $V_r(\mF)=V(M_r(\mF))$. Thus, for
$\mF$ of size $p \times q$, with $p \le q$, 
$$\VpF{p}{\mF}=\{\bx \in \KKbar{}^n \mid \mathrm{rank}(\mF({\bx})) < p\}$$
and $\VpFG{p}{\mF}{\mG}$ is an algebraic set as it is the intersection of
$V(\mG)$ with $\VpF{p}{\mF}$.

% We refer to e.g.~\cite[Chap.\ I and II]{Shafarevich77} for notions related to
% dimension and irreducible components of algebraic sets.
Results due to Macaulay~\cite{Macaulay16} and Eagon and Northcott~\cite{EN62}
imply that all irreducible components of $\VpF{p}{\mF}$ have co-dimension at
most $q-p+1$. Hence, the irreducible components of $\VpFG{p}{\mF}{\mG}$ have
co-dimension at most $q-p+s+1$. Hence, for the above problem, it is natural to
assume that $n = q-p+s+1$.

Even under this assumption, $\VpFG{p}{\mF}{\mG}$ may have positive dimensional
components but we will be interested in describing only its {\em isolated
  points}, that is, the points in the irreducible components of
$\VpFG{p}{\mF}{\mG}$ of dimension zero (this notion makes sense for any
algebraically closed field $\KK$; when $\KK=\mathbb{C}$, these points are indeed
isolated for the metric topology).
Our main problem is then the following.
\begin{pbm} \label{problem2} For $\mF \in \KK[X_1,\dots,X_n]^{p \times q}$ and
  $\mG=(g_1,\dots,g_s)$ in $\KK[X_1,\dots,X_n]$ such that $p \leq q$ and $n =
  q-p+s+1$, compute the isolated points of $\VpFG{p}{\mF}{\mG}$.
\end{pbm}

This problem appears in a variety of context; prominent examples are
optimization problems~\cite{GSZ10,JP14,BGHS14,GS14,NDS06}, and related questions
in real algebraic
geometry~\cite{ARS,BaGiHeMb01,BaGiHePa05,BGHSS,BRSS,RealDecompICMS,CellDecompSurface,BertiniReal,RealNumerical,SaSc03,SaSc11,SaSc17},
where $\mF$ consists of the Jacobian matrix of $\mG$, together with one extra
row, corresponding to the gradient of a function that we want to optimize on
$V(\mG)$. We will refer to this particular class of inputs as systems {\em
  coming from optimization}. %  (in such cases, $q=n$ and $p=s+1$, so our assumption
% $n=q-p+s+1$ holds).

In several of these situations, we are only interested in the solutions of the
system made of minors $M_p(\mF)$ and $\mG=(g_1,\dots,g_s)$ at which the
associated Jacobian matrix has full rank. This set of solutions is finite and is
always contained in the set of isolated points of $\VpFG{p}{\mF}{\mG}$
\cite[Theorem 16.19]{Eisenbud95}; we call these points {\em simple points}. % For
% instance, the set of simple points coincides with $\VpFG{p}{\mF}{\mG}$ when the
% minors $M_p(\mF)$ and $g_1,\dots,g_s$ generate a radical ideal of dimension
% zero; this case appears frequently in algorithms in real algebraic
% geometry~\cite{BGHSS}. 
Hence, we also consider the following variant of
Problem~\eqref{problem2}.

\begin{pbm} \label{problem3} For 
  $\mF \in \KK[X_1,\dots,X_n]^{p \times q}$ and 
  $\mG=(g_1,\dots,g_s)$ in $\KK[X_1,\dots,X_n]$ with $p \leq q$ and
  $n = q-p+s+1$, compute the simple  points of~$\VpFG{p}{\mF}{\mG}$.
\end{pbm}

We will represent the output of our algorithms using univariate polynomials. Let
$V \subset \KKbar{}^n$ be a zero-dimensional algebraic set defined over $\KK$. A
\emph{zero-dimensional parametrization} $\scrR = ((w,v_1, \ldots, v_n),
\lambda)$ of $V$ consists of polynomials $(w,v_1, \ldots, v_n)$ such that $w$ 
is in
$\KK[Y]$ ($Y$ is a new variable), monic and squarefree, all $v_i$'s are in
$\KK[Y]$ and satisfy $\deg(v_i) < \deg(w)$, and $\lambda$ is a $\KK$-linear form
in $n$ variables, such that
\begin{itemize}
\item $\lambda(v_1, \ldots, v_n) = Yw'$ mod $w$, with $w'=\frac{d w}{d Y}$;
\item we have $V = Z(\scrR)$, with $$Z(\scrR)= \left\{\left(\frac{v_1(\tau)}{w'(\tau)}, \ldots, \frac{v_n(\tau)}{w'(\tau)}\right) \ | \ w(\tau) = 0\right\}.$$
\end{itemize}
% The constraint on $\lambda$ then says that the roots of $w$ are the
% values taken by $\lambda$ on $V$. 
This representation was introduced in~\cite{Kronecker82,Macaulay16}, and has
been used in a variety of
algorithms~\cite{GiMo89,GiHeMoPa95,ABRW,GiHeMoMoPa98,Rouillier99,GiLeSa01}. We
use a rational parametrization, with $w'$ as a denominator, as
in~\cite{ABRW,Rouillier99,GiLeSa01} to control precisely the bit-size of the
coefficients when $\KK=\Q$ or the degrees in $T$ when $\KK=k(T)$, for a field
$k$ (see~\cite{Schost03,DaSc04}). 

{\bf Main results.} Our first result gives bounds on the number of solutions of
$\VpFG{p}{\mF}{\mG}$, counted with {\em multiplicities}. We will consider two
degree measures for the matrix $\mF$ which have been used before in~\cite{NieRan09,MiSt04}. For
$i=1,\dots,p$, we will write $\rdeg(\mF,i)$ for the degree of the $i$th row of
$\mF$, that is, $\rdeg(\mF,i)=\max(\deg(f_{i,j}))_{1 \le j \le q}$; similarly,
for $j=1,\dots,q$, we write $\cdeg(\mF,j)$ for the degree of the $j$th column of
$\mF$, that is, $\cdeg(\mF,j)=\max(\deg(f_{i,j}))_{1 \le i \le p}$. Further, for
$k \ge 0$ and integers $\delta_1,\dots,\delta_q$,
$$E_k(\delta_1,\dots,\delta_q)=\sum_{1\leq i_1 < \cdots < i_k \leq
  q}\delta_{i_1} \cdots \delta_{i_k}$$ is the elementary symmetric
polynomial of degree $k$ in $(\delta_1, \ldots, \delta_q)$; 
for integers $\alpha_1,\dots,\alpha_p$,
$$S_k(\alpha_1,\dots,\alpha_p) = \sum_{i_1+\cdots+i_p=k, i_j \geq
  0}\alpha_1^{i_1}\cdots\alpha_p^{i_p}$$ is the $k$th complete
symmetric polynomial in $(\alpha_1,\dots,\alpha_p)$.

Finally, we recall the notion of multiplicity of a point $\bx$ with respect to
an ideal $I$ in $\KKbar[X_1,\dots,X_n]$; it extends to ideals in
$\KK[X_1, \ldots, X_n]$ by considering their extension in $\KKbar[X_1, \ldots,
X_n]$. The ideal $I$ can be written
as % a ``minimal'' intersection of finitely many primary components, that is,
$I=Q_1\cap\cdots \cap Q_r$ for some primary ideals $Q_1,\dots,Q_r$; with
$V(Q_i)\neq V(Q_j)$ for $i\neq j$. Take $\bx$ isolated in $V(I)$; then there
exists a unique primary component $Q_i$, which must have dimension zero, such
that $\bx$ is in $V(Q_i)$. Because we take a primary decomposition over
$\KKbar$, we actually have $V(Q_i)=\{\bx\}$. % Although minimal primary
% decompositions are not unique, t
The fact that $\bx$ is isolated implies
that $Q_i$ does not depend on the primary decomposition of $I$ we
consider. Then, the \emph{multiplicity} of $\bx$ is defined as the
dimension of $\KKbar[X_1,\dots,X_n]/Q_i$. % When $\bx=0\in\KKbar{}^n$,
% the dimension of $\KKbar[X_1,\dots,X_n]/Q_i$ is the same as that of
% $\KKbar[[X_1, \ldots, X_n]]/I$, where $\KK[[X_1, \ldots, X_n]]$
% denotes the formal power series ring in $X_1, \ldots, X_n$ with
% coefficients in $\KKbar$~\cite[Theorem 4.2.2]{CLO_UAG}.

%All this being said, the following is our first~result.

\begin{theorem}\label{theo:1}
  Let $\mF$ be in $\KK[X_1,\dots,X_n]^{p \times q}$ and let
  $\mG=(g_1,\dots,g_s)$ be in $\KK[X_1,\dots,X_n]$, with $p \le q$ and
  $n=q-p+s+1$. Then, the sum of the multiplicities of the isolated
  points of the ideal generated by the $p$-minors of $\mF$ and 
$ g_1,\dots,g_s$ is at most
  $\min(c,c')$ with
$$c=\deg(g_1) \cdots \deg(g_s) E_{n-s}(\cdeg(\mF,1), \ldots, \cdeg(\mF,q))$$
and
$$c'=\deg(g_1) \cdots \deg(g_s) S_{n-s}(\rdeg(\mF,1), \ldots, \rdeg(\mF,p)).$$
\end{theorem}

When $\rdeg(\mF,i)=\cdeg(\mF,j)=d$ for all $i,j$, both bounds given above
coincide to $\deg(g_1) \cdots \deg(g_s) {q \choose {p-1}} d^{n-s}$. Else,
either of the two expressions can be the minimum.

Our second result gives bounds on the cost of computing a
zero-dimensional paramet\-rization of the isolated solutions of
$\VpFG{p}{\mF}{\mG}$. Our
algorithms take as input a \emph{straight-line program} (that is, a
sequence of elementary operations $+, -, \times$) that computes the
entries of $\mF$ and $\mG$; the
\emph{length $\sigma$} of the input is the number of operations it
performs. This assumption is not restrictive as $\mF$
and $\mG$ can be computed by a straight-line program (a
naive solution would consist in computing and adding all monomials in
$\mF$ and $\mG$).

\begin{theorem}\label{theo:2}
  Suppose that $\mF \in \KK[X_1,\dots,X_n]^{p \times q}$ and 
  $\mG=(g_1,\dots,g_s)$ in $\KK[X_1,\dots,X_n]$ are given by a straight-line
  program of length $\sigma$ and that $\deg(g_1),\dots,\deg(g_s)$, as well
  as $\cdeg(\mF,1), \ldots, \cdeg(\mF,q)$ and $\rdeg(\mF,1), \ldots,
  \rdeg(\mF,p)$ are all at least equal to $1$.

  Then, there exist randomized algorithms that solve
  Problem~\eqref{problem2} in either
   $$\softO\left (
     {q \choose p} c(e+c^5 )\big(\sigma + q \delta + \gamma  \big )
   \right)$$
  operations in $\KK$, with
  \begin{align*}
    c&=\deg(g_1)\cdots\deg(g_s)\ E_{n-s}(\cdeg(\mF,1), \ldots, \cdeg(\mF,q))\\
    e&=(\deg(g_1)+1)\cdots(\deg(g_s)+1)\ E_{n-s}(\cdeg(\mF,1)+1, \ldots, \cdeg(\mF,q)+1),\\
    \gamma&= \max(\deg(g_i), 1\leq i \leq s)\\
    \delta &= \max(\cdeg(\mF,i), 1\leq i \leq q)
  \end{align*}
  or 
   $$\softO\left (
     {q \choose p} c'(e'+{c'}^5 )\big(\sigma + p \alpha  +\gamma \big )
   \right)$$
  operations in $\KK$, with 
\begin{align*}
  c'&=\deg(g_1)\cdots\deg(g_s)\ S_{n-s}(\rdeg(\mF,1), \ldots, \rdeg(\mF,p))\\
  e'&=(\deg(g_1)+1)\cdots(\deg(g_s)+1)\ S_{n-s}(\rdeg(\mF,1)+1, \ldots, \rdeg(\mF,p)+1),\\
    \gamma&= \max(\deg(g_i), 1\leq i \leq s)\\
    \alpha &= \max(\rdeg(\mF,j), 1\leq j \leq p).
\end{align*}
\end{theorem}
\added{The assumption that all degrees are at least $1$ is not a strong
  restriction. If $\deg(g_i)=0$ for some $i$, $g_i$ is a constant. So either the
  system is inconsistent (if $g_i \ne 0$) or $g_i$ can be discarded, $s$
  decreases and $n > q-p+s+1$ after this update which implies that there is no
  isolated point in $\VpFG{p}{\mF}{\mG}$. Similarly, if say $\cdeg(\mF,i)=0$,
  the $i$th column of $\mF$ consists of constants. After applying linear
  combinations with coefficients in $\KK$ to the rows of $\mF$, we may assume
  that all entries in the $i$th column, except at most one, are zero without
  changing the column degrees. The $i$th column of $\mF$ and the row of the
  non-zero entry can then be discarded ; $p$ and $q$ decrease by $1$ and we
  still have $n= q-p+s+1$.}

Remark further that in the common situation where all degrees $\deg(g_i)$,
$\rdeg(\mF,i)$ and $\cdeg(\mF,j)$ involved in the formulas above are at least
equal to $2$, we have the inequalities $e \le c^2$, $e' \le {c'}{}^2$ and
$\binom{q}{p}\leq c$, $\binom{q}{p}\leq c'$. As a result, the runtimes are {\em
  polynomial} in $c,\sigma$ and $c',\sigma$: they respectively become $\softO
(c^8 \sigma)$ and $\softO ({c'}^8 \sigma)$ \added{(but recall that $c, c'$
  become $d^n\binom{q}{p-1}$ when $\cdeg(\mF, i)=\rdeg(\mF, j)=\deg(g_k)=d$ for
  all $i,j,k$)}. Note that by Theorem~\ref{theo:1}, 
that $\min(c,c')$ is an upper bound for the output size of
such~algorithms.

For solving Problem~\eqref{problem3}, one obtains slightly better
complexity estimates. 

\begin{theorem}\label{theo:3}
  Suppose that the matrix $\mF \in \KK[X_1,\dots,X_n]^{p \times q}$
  and polynomials $\mG=(g_1,\dots,g_s)$ in $\KK[X_1,\dots,X_n]$ are
  given by a straight-line program of length $\sigma$. Assume that
  $\deg(g_1),\dots,\deg(g_s)$, as well as
  $\cdeg(\mF,1), \ldots, \cdeg(\mF,q)$ and
  $\rdeg(\mF,1), \ldots, \rdeg(\mF,p)$ are all at least equal to $1$.

  Then, there exist randomized algorithms that solve
  Problem~\eqref{problem3} in either
   $$\softO\left (
     {q \choose p} ce\big(\sigma + q \delta + \gamma  \big )
   \right)$$
or 
   $$\softO\left (
     {q \choose p} c'e'\big(\sigma + p \alpha  +\gamma \big )
   \right)$$
  operations in $\KK$, 
  all notations being as in Theorem~\ref{theo:3}.
\end{theorem}
As above, in the common situation where all degrees involved are at
least $2$, the runtimes are {\it polynomial} in $c, \sigma$ and
$c',\sigma'$; they respectively become $\softO (c^5 \sigma)$ and $\softO
({c'}^5 \sigma)$.


The probabilistic aspects are as follows: at several steps, the
algorithms on which Theorems~\ref{theo:2} and~\ref{theo:3} rely will
draw elements from the base field at random. In all cases, there
exists an algebraic hypersurface $\cal H$ of the parameter space such
that success is guaranteed for all choices of parameters not
in~$\cal H$.

{\bf Prior works.} Although results in a vein similar to Theorem~\ref{theo:1}
have already been published, we are not aware of previous statements as above,
with no assumption on the dimension of $V_p(\mF,\mG)$, and that take into
account multiplicities as is done in Theorem~\ref{theo:1}.

Pioneering work of Giambelli-Thom-Porteous (see e.g. \cite{FP06} or
\cite{Fu92}) already established similar bounds under regularity
assumptions (when $V(\mG)$ is smooth and/or $V_p(\mF, \mG)$ has the
expected dimension). Previous work by Miller and
Sturmfels~\cite[Chapter~15]{MiSt04} proved general results on the
multi-degrees of determinantal ideals built from matrices with
indeterminate entries (here $s=0$, but the assumption
$n=q-p+1$ does not hold); they obtain analogues (and
generalizations) of the result in Theorem~\ref{theo:1} in that
context.

Nie and Ranestad proved in~\cite{NieRan09} that the bounds in
Theorem~\ref{theo:1} are tight for two families of polynomials
% (in a similar context where the polynomials are homogeneous in
% $n+1$ variables):
\begin{itemize}
\item when entries of $\mF$ are generic and homogeneous, and
 such that $\deg(f_{i,j}) = \cdeg(\mF,j)$ for all $i,j$, the ideal
 generated by $M_p(\mF)$ has degree $E_{n}(\cdeg(\mF,1), \ldots, \cdeg(\mF,q))$;
\item when entries of $\mF$ are generic and homogeneous, and such that
  $\deg(f_{i,j}) = \rdeg(\mF,i)$ for all $i,j$, the ideal generated by
  $M_p(\mF)$ has degree $S_{n}(\rdeg(\mF,1), \ldots, \rdeg(\mF,p))$.
\end{itemize}
From this, they deduce that the degree of the ideal generated by the
$p$-minors of $\mF$ and $ g_1,\dots,g_s $ is at most \sloppy
$\deg(g_1) \cdots \deg(g_s) S_{n-s}(\rdeg(\mF,1), \ldots,
\rdeg(\mF,p))$, for systems coming from optimization, assuming that
this ideal has dimension zero. Spaenlehauer also gave
in~\cite{Spa14} explicitely the Hilbert function of the
ideal above, for a generic input.


Our algorithms are based on a {\em symbolic homotopy continuation}. Following
early work in the 1930's, such as~\cite{Lahaye34}, homotopy continuation
algorithms have become a foundational tool for numerical algorithms. We mention for
instance~\cite{AlGe03} for an extensive list of references, Shub and Smale's
work on the complexity of these techniques (see e.g.~\cite{ShSm93}), or
works by Morgan, Sommese, Wampler emphasizing the underlying algebraic geometry
(see e.g.~\cite{BertiniBook,SoWa05}), as well
as~\cite{Ver94,Ver09,AdVe13} for dedicated numerical homotopy algorithms to take
into account sparsity in polynomial systems.

By contrast, the usage of homotopy methods in symbolic contexts is
more recent% , even though some early results, such as Bernstein's proof
% of the so-called BKK theorem, already involve Puiseux series
% manipulations~\cite{Bernstein75}
. References such
as~\cite{HeKrPuSaWa99,BoMaWaWa04} deal with systems with no particular
structure, or systems with no zeros at infinity~\cite{PaSa04}.
Further work extended this idea to sparse systems (in the polyhedral
sense)~\cite{JeMaSoWa09,HeJeSa10,HeJeSa13,HeJeSa14} and
multihomogeneous systems~\cite{HeJeSaSo02,SaSc16}.  In~\cite{SaSc16},
these techniques are used to solve Problem~\eqref{problem3}, but the
complexity estimates obtained there depend on multi-homogeneous
B\'ezout bounds involving the maxima of $\rdeg(\mF, 1), \ldots,
\rdeg(\mF, p)$ or $\cdeg(\mF,1), \ldots, \cdeg(\mF, q)$.

Most aforementioned algorithms solve {\em square} systems, that is, systems with
as many equations as unknowns; though extensions can deal with systems of
positive dimension by using variants of algorithms for square systems. Note that
using slack variables as in \cite{SoVe00}, polyhedral homotopies apply to
overdetermined systems but the control of their complexities is not known. Some
dedicated homotopies have been designed for special overdetermined systems as in
\cite{BV00, SVV10}.
% One
% notable exception is \cite{SVV10}, providing dedicated homotopy algorithms to
% solve Schubert problems which are formulated with rank conditions on some
% special matrices~\cite{LDSVV18}. These work through the Littlewood Richardson
% rule and some combinatorial construction. 
As far as we know, they cannot be used
to solve determinantal systems as the ones we tackle in this paper.

In this paper, we deal with determinantal
systems of equations, which are in essence over-determined; this is
made possible by the algebraic properties of determinantal ideals.

Starting from the determination of the Hilbert function of a determinantal ring
due to Conca and Herzog~\cite{CH94}, complexity estimates are given in
\cite{FSS13,FSS12} for computing Gr\"obner bases of ideals generated by either
$M_r(\mF)$ when $r\leq p\leq q$, or $M_{p}(\mF),g_1,\dots,g_s$, (for inputs
coming from optimization problems), but under some genericity assumptions on the
entries of $\mF$ or $\mG$; also the input polynomials must have all the same
degree. Thes works culminated with the result by Spaenlehauer in \cite{Spa14}:
he removes this latter degree assumption and provides sharp complexity
statements, still under genericity assumptions.

Systems encoding rank defects in polynomial matrices have also been studied in
the scope of the so-called geometric resolution algorithm in
\cite{BaGiHeLeMaSo15} and \cite{SaSp16}. The algorithms in these references
solve only Problem~\eqref{problem3} (isolated solutions which are not simple are
not considered in that line of work). \added{Computing isolated points of
  $\VpFG{p}{\mF}{\mG}$ could be done using Lecerf's equidimensional
  decomposition algorithm, still based on the geometric resolution \cite{Lecerf2000}. }
The cost of these algorithms is quadratic in certain geometric quantities (the
degree of algebraic sets defined by subsystems of the determinantal equations we
are dealing with); this is to be compared with the runtimes in
Theorem~\ref{theo:3}, where the main contributions are the products ${q \choose
  p} c e$, respectively ${q \choose p} c' e'$, and where $ce$, resp.\ $c'e'$,
are also of a geometric nature. Further work is needed to compare the degrees
involved in these complexity estimates with ours, and the resulting runtimes.

{\bf Overview of the paper and illustration of the main results.} We start with
$\mF$ and $\mG$ as above and build the equations
$\bC=(c_1,\dots,c_{s},\dots,c_m)$ that we want to solve:
$(c_1,\dots,c_{s})=(g_1,\dots,g_s)$, and $(c_{s+1},\dots,c_{m})$ are the
$p$-minors of $\mF$.

\begin{example}\label{ex:1}
  Throughout the paper, we will consider the following example, with $\KK=\Q$,
  $n=2$, $p=2$ and $q=3$ (so $n=q-p+1$), and we let $\mF \in \K[X_1,X_2]^{2
    \times 3}$ be given by
  $$\mF=\begin{bmatrix}
  X_1+X_2-1 & 3X_1+5X_2+2  & 10X_1+X_2-1\\
  X_2^2+X_1+10X_2+3   & X_1^2+3X_1X_2+X_1-1  & X_1^2-4X_1X_2+X_2^2+3
  \end{bmatrix}.$$
  The maximal minors $\bC=M_2(\mF)$ of this matrix are
  \begin{align*}
   c_1&= -7X_1^3 - 38X_1^2X_2 - 7X_1^2 - 20X_1X_2^2 - 6X_1X_2 + 20X_1 + 5X_2^3 +    2X_2^2 + 16X_2 + 5,\\
   c_2&=    X_1^3 - 3X_1^2X_2 - 11X_1^2 - 13X_1X_2^2 - 97X_1X_2 - 26X_1 - 10X_2^2 +    10X_2,\\
   c_3&=    X_1^3 + 4X_1^2X_2 - 3X_1^2 - 37X_1X_2 - 13X_1 - 5X_2^3 - 52X_2^2 - 36X_2 - 5.
  \end{align*}
%  They have $7$ common solutions, which we will describe below.
\end{example}


As a preliminary, we will need an algorithm which takes as input polynomials
$\bC$ and a point $\bx$ in the zero-set of $\bC$, and which decides whether
$\bx$ is an isolated point of $V(\bC)$ (this will be used to solve
Problem~\eqref{problem2}). When a bound $\mu$ is known on the multiplicity of
$\bx$ as a root of $\bC$, it becomes possible to solve this problem in time
polynomial in the number of equations $m$, the number of variables $n$, the
bound $\mu$, and the complexity of evaluation $\sigma$ of $\bC$. This is
detailed in Section~\ref{sec:isolated}, where we explain how to modify an
algorithm by Mourrain~\cite{Mourrain97} and adapt it to our context.

\begin{example}\label{ex:2}
  In Example~\ref{ex:1}, the maximal minors $\bC = M_2(\mF)$ generate a radical
  ideal of dimension zero, so Problems~\ref{problem2} and~\ref{problem3} admit the same
  answer. There are 7 solutions, which are described by means of the univariate
  representation $\scrR=((w,v_1,v_2),\lambda)$, with 
{\small  \begin{align*}
w &= Y^7 + \frac{5249}{285}Y^6 + \frac{5899}{76}Y^5 - \frac{32593}{950}Y^4 - \frac{719401}{5700}Y^3 
        - \frac{302473}{5700}Y^2 - \frac{1243}{475}Y + \frac{379}{1140}\\[1mm]
v_1&= -\frac{461}{114}Y^6 - \frac{39047}{380}Y^5 - \frac{2431807}{2850}Y^4 - \frac{87697}{76}Y^3 - \frac{560363}{1900}Y^2 
      + \frac{64121}{570}Y + \frac{1341}{76}\\[1mm]
v_2 &= -\frac{5249}{285}Y^6 - \frac{5899}{38}Y^5 + \frac{97779}{950}Y^4 + \frac{719401}{1425}Y^3 
       + \frac{302473}{1140}Y^2 + \frac{7458}{475}Y - \frac{2653}{1140}.
         \end{align*}}
       and $\lambda = X_2$. The coordinates of the solutions are the values taken by $(v_1/w',v_2/w')$
       at the roots of $w$.

    In our example, we have no polynomials $\mG$, so $s=0$. The column degrees of
  $\mF$ are $(\cdeg(\mF,1),\cdeg(\mF,2),\cdeg(\mF,3))=(2,2,2)$, whereas its
  row degrees are $(\rdeg(\mF,1),\rdeg(\mF,2))=(1,2)$. 
  Using Theorem~\ref{theo:1}, the column degree bound is $c=E_2(2,2,2) = 2^2 + 2^2 +
  2^2 =12$, the row degree bound is $c'=S_2(1,2) = 1^2 + 1\cdot 2 +
  2^2 = 7$. The latter is sharp ; it can be used for the bound $\mu$ we
  mentioned above.
\end{example}


In order to compute the isolated points, or the simple points, of
$V(\bC)$, we work with a deformation of these equations.  We let $T$ be a
new variable, and we define 
polynomials $\bV=(v_1,\dots,v_s)$ of the form
\begin{equation}\label{eqdef:bV}
\bV = (1-T) \cdot \bM + T \cdot \mG,  
\end{equation}
that connect certain polynomials $\bM=(m_1,\dots,m_s)$ to the target
system $\mG$, together with 
the matrix
\begin{equation}\label{eqdef:bU}
\bU = (1-T)\cdot \bL + T \cdot \mF \in \KK[T, X_1,\dots,X_n]^{p \times q}  
\end{equation}
that connects a suitable \emph{start matrix} $\bL$ to the target matrix $\mF$.
\begin{itemize}
\item The {\em start system} $\bA=(a_1,\dots,a_m)$ will be defined by
  taking $(a_1,\dots,a_s) = (m_1,\dots,m_s)$, and by letting
  $(a_{s+1},\dots,a_m)$ be the $p$-minors of $\bL$; these polynomials 
  are in $\KK[X_1,\dots,X_n]$. 
\item The parametric system $\bB=(b_1,\dots,b_m)$ will be defined by
  taking $(b_1,\dots,b_s) = (v_1,\dots,v_s)$, and by letting
  $(b_{s+1},\dots,b_m)$ be the $p$-minors of $\bU$; these polynomials 
  are in $\KK[T,X_1,\dots,X_n]$. 
\end{itemize}
In particular, setting $T=0$ in $\bB$ gives us $\bA$, and 
setting $T=1$ in it recovers $\bC$.

In Sections~\ref{sec:check} and~\ref{sec:homotopy}, we prove a few
properties of the ideal generated by $\bB$, independently of the
choices of $\bL$ and $\bM$.  Then, in Section~\ref{sec:homotalgo}, we
give symbolic homotopy algorithms which take as input the sequence of
polynomials $\bB$, together with a description of $V(\bA)$ (under
certain regularity assumptions), and computes a zero-dimensional
parametrization of either the isolated solutions, or the simple
solutions of $\bC$. % This is done by lifting the points of $V(\bA)$
% (that correspond to $T=0$) into a curve $\cal C$ parametrized by
% $T$. The isolated points of $V(\bC)$ all belong to the fiber of $\cal
% C$ above $T=1$, but some points in this fiber can actually lie in
% positive dimensional components of $V(\bC)$; the algorithm of
% Section~\ref{sec:isolated} will filter out such points. To find simple
% points, the procedure will be slightly simpler.

To give concrete algorithms, we will have to specify how to define
polynomials $\bM$ and matrix $\bL$, and how to find the solutions of 
$\bA=0$.
The main difficulty lies in the definition of a matrix
$\bL$ that will respect either the column-degree or the row-degree of
$\mF$, while satisfying all assumptions needed for the algorithm of
Section~\ref{sec:homotalgo} and allowing us to solve
the resulting system $\bA=0$ easily.
  The column-degree case is treated in
Section~\ref{sec:columndegree} in a rather straightforward way,
whereas the row-degree case is more delicate, and is treated in
Sections~\ref{sec:prel-row} and~\ref{sec:rowdegree}. The proofs of
some properties needed in the latter sections are postponed to the
appendix of the paper.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \newpage
% Throughout, $\KK$ is a field of characteristic zero with algebraic
% closure $\KKbar$, $(X_1, \ldots, X_n)$ is a set of $n$ variables, and
% $\KK[X_1,\dots,X_n]$ is the multivariate polynomial ring in $n$
% variables with coefficients in $\KK$.  With this setup, let
% $\mF=[f_{i,j}] \in \KK[X_1,\dots,X_n]^{p \times q}$ be a polynomial
% matrix, with $p \leq q$. The first question which will interest us in
% this paper is to describe the set of points $\x \in \KKbar{}^n$ at
% which the evaluation of the matrix $\mF$ has rank less than $p$.  In
% the particular case $p=1$, this simply means finding all common
% solutions of $f_{1,1},\dots,f_{1,q}$.

% For any matrix $\mF$ over a ring $R$, and for any integer $r$,
% $M_r(\mF)$ will denote the set of $r$-minors of $\mF$. For any subset $I$ in
% $\KK[X_1,\dots,X_n]$, $V(I)$ will denote the zero-set of $I$ in
% $\KKbar{}^n$, and for a matrix $\mF$ with entries in
% $\KK[X_1,\dots,X_n]$, we will write $V_r(\mF)=V(M_r(\mF))$. Thus, for
% $\mF$ of size $p \times q$, with $p \le q$, the set of points
% introduced in the previous paragraph is
% $$\VpF{p}{\mF}=\{\bx \in \KKbar{}^n \mid \mathrm{rank}(\mF({\bx})) < p\}.$$
% This is an algebraic set, since it is defined by the vanishing of
% all maximal minors of $\mF$. 

% We will discuss below dimension properties of $\VpF{p}{\mF}$.  Recall
% that any algebraic set $V$ is the finite union of its
% \emph{irreducible components}: these are the maximal irreducible
% algebraic sets contained in it (an algebraic set is irreducible if it
% is not the union of two proper algebraic sets). The {\em dimension} of
% an algebraic set $V$ is the largest integer $d$ such that intersecting
% $V$ with $d$ generic hyperplanes yields finitely many points; those
% algebraic sets with all irreducible components of the same dimension
% are called {\em equidimensional}. We refer to
% e.g.~\cite[Chap.\ I and II]{Shafarevich77} for these notions.

% For the problem above, it is natural to consider the case where $n = q-p+1$.
% Indeed, results due to Macaulay~\cite{Macaulay16} and Eagon and
% Northcott~\cite{EN62} imply that all irreducible components of $\VpF{p}{\mF}$
% have dimension at least $n-(q-p+1)$; furthermore, in the case $n = q-p+1$,
% $\VpF{p}{\mF}$ has dimension zero for a generic choice of the entries of $\mF$
% (this is proved for instance in~\cite{Spa14}). Of course, even if we assume $n =
% q-p+1$, $\VpF{p}{\mF}$ may have components of positive dimension; in this case,
% we will be interested in describing only its {\em isolated points}, that is, the
% points in the irreducible components of $\VpF{p}{\mF}$ of dimension zero (this
% notion makes sense for any algebraically closed field $\KK$; when
% $\KK=\mathbb{C}$, these points are indeed isolated for the metric topology).

% \begin{example}\label{ex:1}
%   Several algorithms in this paper will be illustrated by the
%   following example, where we take $\KK=\Q$, $n=2$, $p=2$ and $q=3$
%   (so $n=q-p+1$), and we let $\mF \in \K[X_1,X_2]^{2 \times 3}$ be
%   given by
%   $$\mF=\begin{bmatrix}
%   X_1+X_2-1 & 3X_1+5X_2+2  & 10X_1+X_2-1\\
%   X_2^2+X_1+10X_2+3   & X_1^2+3X_1X_2+X_1-1  & X_1^2-4X_1X_2+X_2^2+3
%   \end{bmatrix}.$$
%   The maximal minors $\bC=M_2(\mF)$ of this matrix are
%   \begin{align*}
%    c_1&= -7X_1^3 - 38X_1^2X_2 - 7X_1^2 - 20X_1X_2^2 - 6X_1X_2 + 20X_1 + 5X_2^3 +    2X_2^2 + 16X_2 + 5,\\
%    c_2&=    X_1^3 - 3X_1^2X_2 - 11X_1^2 - 13X_1X_2^2 - 97X_1X_2 - 26X_1 - 10X_2^2 +    10X_2,\\
%    c_3&=    X_1^3 + 4X_1^2X_2 - 3X_1^2 - 37X_1X_2 - 13X_1 - 5X_2^3 - 52X_2^2 - 36X_2 - 5.
%   \end{align*}
%   They have $7$ common solutions, which we will describe below.
% \end{example}



% Studying the set $\VpF{p}{\mF}$ is a particular case of a slightly
% more general question. In addition to matrix $\mF$, we may indeed take
% into account further equations of the form $g_1 =\cdots=g_s=0$, for
% some $\mG=(g_1,\dots,g_s)$ in $\KK[X_1,\dots,X_n]$. In this setting, the
% natural relation between the number $n$ of variables, the size of
% $\mF$ and the number $s$ of polynomials in $\mG$ is now
% $n=q-p+s+1$. Then, we define the algebraic set
% $$\VpFG{p}{\mF}{\mG} = \{\bx \in \KKbar{}^n \mid
% \mathrm{rank}(\mF({\bx})) < p \text{~and~} g_1(\bx)=\cdots=g_s(\bx)=0
% \};$$ this is thus the zero-set of the ideal generated by the
% $p$-minors of $\mF$ and $ g_1,\dots,g_s$. Our main problem is then the following.
% \begin{pbm} \label{problem2} 
%   For a field $\KK$, a matrix $\mF \in \KK[X_1,\dots,X_n]^{p \times q}$ and
%   polynomials $\mG=(g_1,\dots,g_s)$ in $\KK[X_1,\dots,X_n]$ such that 
%   $p \leq q$ and   $n = q-p+s+1$, compute the isolated points of $\VpFG{p}{\mF}{\mG}$.
% \end{pbm}
% This problem appears in a variety of context; prominent examples are
% optimization problems~\cite{GSZ10,JP14,BGHS14,GS14,NDS06}, and related
% questions in real algebraic
% geometry~\cite{ARS,BaGiHeMb01,BaGiHePa05,BGHSS,BRSS,RealDecompICMS,CellDecompSurface,BertiniReal,RealNumerical,SaSc03,SaSc11,SaSc17},
% where $\mF$ consists of the Jacobian matrix of $\mG$, together with
% one extra row, corresponding to the gradient of a function that we
% want to optimize on $V(\mG)$. Because they show up several times in
% this introduction, we will refer to this particular class of inputs as
% systems {\em coming from optimization} (in such cases, $q=n$ and $p=s+1$, 
% so our assumption $n=q-p+s+1$ holds).

% In several of these situations, we are only interested in the
% solutions of the system made of minors $M_p(\mF)$ and
% $\mG=(g_1,\dots,g_s)$ at which the associated Jacobian matrix has full
% rank. This set of solutions is finite and is always contained in the
% set of isolated points of $\VpFG{p}{\mF}{\mG}$ \cite[Theorem
%   16.19]{Eisenbud95}; we call these points {\em simple points}. For
% instance, the set of simple points coincides with $\VpFG{p}{\mF}{\mG}$
% when the minors $M_p(\mF)$ and $g_1,\dots,g_s$ generate a radical
% ideal of dimension zero; this case appears frequently in the context
% of algorithms in real algebraic geometry~\cite{BGHSS}.  Hence, it also
% makes sense to look at the following slight variant of
% Problem~\eqref{problem2}.

% \begin{pbm} \label{problem3} For a field $\KK$, a matrix
%   $\mF \in \KK[X_1,\dots,X_n]^{p \times q}$ and polynomials
%   $\mG=(g_1,\dots,g_s)$ in $\KK[X_1,\dots,X_n]$ with $p \leq q$ and
%   $n = q-p+s+1$, compute the simple  points of~$\VpFG{p}{\mF}{\mG}$.
% \end{pbm}

% We will represent the output of our algorithms using univariate polynomials. Let
% $V \subset \KKbar{}^n$ be a zero-dimensional algebraic set defined over $\KK$. A
% \emph{zero-dimensional parametrization} $\scrR = ((w,v_1, \ldots, v_n),
% \lambda)$ of $V$ consists of polynomials $(w,v_1, \ldots, v_n)$ such that $w$ 
% is in
% $\KK[Y]$ ($Y$ is a new variable), monic and squarefree, all $v_i$'s are in
% $\KK[Y]$ and satisfy $\deg(v_i) < \deg(w)$, and $\lambda$ is a $\KK$-linear form
% in $n$ variables, such that
% \begin{itemize}
% \item $\lambda(v_1, \ldots, v_n) = Yw'$ mod $w$, with $w'=\frac{d w}{d Y}$;
% \item we have $V = Z(\scrR)$, with $$Z(\scrR)= \left\{\left(\frac{v_1(\tau)}{w'(\tau)}, \ldots, \frac{v_n(\tau)}{w'(\tau)}\right) \ | \ w(\tau) = 0\right\}.$$
% \end{itemize}
% The constraint on $\lambda$ then says that the roots of $w$ are the
% values taken by $\lambda$ on $V$. This representation was introduced
% in~\cite{Kronecker82,Macaulay16}, and has been used in a variety of
% algorithms, such as those
% in~\cite{GiMo89,GiHeMoPa95,ABRW,GiHeMoMoPa98,Rouillier99,GiLeSa01}.
% The reason why we use a rational parametrization, with $w'$ as a
% denominator, goes back to~\cite{ABRW,Rouillier99,GiLeSa01}: when
% $\KK=\Q$, this allows us to control precisely the bit-size of the
% coefficients, using bounds such as those
% in~\cite{Schost03,DaSc04}. The same phenomenon holds with $\KK=k(T)$,
% for a field $k$, in which case we want to control degrees in $T$ of
% the numerators and denominators of the coefficients of $\scrR$.


% \begin{example}\label{ex:2}
%   In Example~\ref{ex:1}, the maximal minors $\bC = M_2(\mF)$ generate a radical
%   ideal of dimension zero, so Problems~\ref{problem2} and~\ref{problem3} admit the same
%   answer. There are 7 solutions, which are described by means of the univariate
%   representation $\scrR=((w,v_1,v_2),\lambda)$, with $\lambda = X_2$ and
% {\small  \begin{align*}
% w &= Y^7 + \frac{5249}{285}Y^6 + \frac{5899}{76}Y^5 - \frac{32593}{950}Y^4 - \frac{719401}{5700}Y^3 
%         - \frac{302473}{5700}Y^2 - \frac{1243}{475}Y + \frac{379}{1140}\\[1mm]
% v_1&= -\frac{461}{114}Y^6 - \frac{39047}{380}Y^5 - \frac{2431807}{2850}Y^4 - \frac{87697}{76}Y^3 - \frac{560363}{1900}Y^2 
%       + \frac{64121}{570}Y + \frac{1341}{76}\\[1mm]
% v_2 &= -\frac{5249}{285}Y^6 - \frac{5899}{38}Y^5 + \frac{97779}{950}Y^4 + \frac{719401}{1425}Y^3 
%        + \frac{302473}{1140}Y^2 + \frac{7458}{475}Y - \frac{2653}{1140}.
%   \end{align*}}
%   The coordinates of the solutions are the values taken by $(v_1/w',v_2/w')$
%   at the roots of $w$. 
% \end{example}


% Our first result gives bounds on the number of solutions of
% $\VpFG{p}{\mF}{\mG}$, counted with multiplicities. To state it, we
% need the following notation.  Take $\mF=[f_{i,j}]_{1 \le i \le p, 1
%   \le j \le q}$ in $\KK[X_1,\dots,X_n]^{p \times q}$.  We will
% consider two degree measures for the matrix $\mF$; these have been used
% before for determinantal ideals, see for
% instance~\cite{NieRan09,MiSt04}. For $i=1,\dots,p$, we will write
% $\rdeg(\mF,i)$ for the degree of the $i$th row of $\mF$, that is,
% $\rdeg(\mF,i)=\max(\deg(f_{i,j}))_{1 \le j \le q}$; similarly, for
% $j=1,\dots,q$, we write $\cdeg(\mF,j)$ for the degree of the $j$th
% column of $\mF$, that is, $\cdeg(\mF,j)=\max(\deg(f_{i,j}))_{1 \le i
%   \le p}$. Further, for $k \ge 0$ and integers $\delta_1,\dots,\delta_q$,
% $$E_k(\delta_1,\dots,\delta_q)=\sum_{1\leq i_1 < \cdots < i_k \leq
%   q}\delta_{i_1} \cdots \delta_{i_k}$$ is the elementary symmetric
% polynomial of degree $k$ in $(\delta_1, \ldots, \delta_q)$; 
% for integers $\alpha_1,\dots,\alpha_p$,
% $$S_k(\alpha_1,\dots,\alpha_p) = \sum_{i_1+\cdots+i_p=k, i_j \geq
%   0}\alpha_1^{i_1}\cdots\alpha_p^{i_p}$$ is the $k$th complete
% symmetric polynomial in $(\alpha_1,\dots,\alpha_p)$.

% Finally, we recall the notion of multiplicity of a point $\bx$ with
% respect to an ideal $I$ in
% $\KKbar[X_1,\dots,X_n]$; this notion
% extends to ideals in $\KK[X_1, \ldots, X_n]$ by considering their
% extension in $\KKbar[X_1, \ldots, X_n]$. The ideal $I$ can be written
% as the intersection of finitely many primary components, that is,
% $I=Q_1\cap\cdots \cap Q_r$ for some primary ideals $Q_1,\dots,Q_r$;
% this decomposition is said to be minimal when $V(Q_i)\neq V(Q_j)$ for
% $i\neq j$. Take $\bx$ isolated in $V(I)$; then there exists a unique
% primary component $Q_i$, which must have dimension zero, such that
% $\bx$ is in $V(Q_i)$; because we take a primary decomposition over
% $\KKbar$, we actually have $V(Q_i)=\{\bx\}$. Although minimal primary
% decompositions are not unique, the fact that $\bx$ is isolated implies
% that $Q_i$ does not depend on the primary decomposition of $I$ we
% consider; then, the \emph{multiplicity} of $\bx$ is defined as the
% dimension of $\KKbar[X_1,\dots,X_n]/Q_i$. When $\bx=0\in\KKbar{}^n$,
% the dimension of $\KKbar[X_1,\dots,X_n]/Q_i$ is the same as that of
% $\KKbar[[X_1, \ldots, X_n]]/I$, where $\KK[[X_1, \ldots, X_n]]$
% denotes the formal power series ring in $X_1, \ldots, X_n$ with
% coefficients in $\KKbar$~\cite[Theorem 4.2.2]{CLO_UAG}.

% All this being said, the following is our first~result.

% \begin{theorem}\label{theo:1}
%   Let $\mF$ be in $\KK[X_1,\dots,X_n]^{p \times q}$ and let
%   $\mG=(g_1,\dots,g_s)$ be in $\KK[X_1,\dots,X_n]$, with $p \le q$ and
%   $n=q-p+s+1$. Then, the sum of the multiplicities of the isolated
%   points of the ideal generated by the $p$-minors of $\mF$ and 
% $ g_1,\dots,g_s$ is at most
%   $\min(c,c')$ with
% $$c=\deg(g_1) \cdots \deg(g_s) E_{n-s}(\cdeg(\mF,1), \ldots, \cdeg(\mF,q))$$
% and
% $$c'=\deg(g_1) \cdots \deg(g_s) S_{n-s}(\rdeg(\mF,1), \ldots, \rdeg(\mF,p)).$$
% \end{theorem}
% When $\rdeg(\mF,i)=\cdeg(\mF,j)=d$ for all $i,j$, the two bounds given
% above coincide, with common value $\deg(g_1) \cdots \deg(g_s) {q \choose {p-1}} d^{n-s}$; otherwise, either of the two expressions
% $E_{n-s}(\cdeg(\mF,1), \ldots, \cdeg(\mF,q))$ and
% $S_{n-s}(\rdeg(\mF,1), \ldots, \rdeg(\mF,p))$ can be the minimum. 

% %% For 
% %% instance, consider the case where $s=0$ (so there are no equations $\mG$),
% %% and where the degrees of the entries in $\mF$ are 
% %% $$ \begin{bmatrix}
% %%     2 & 1 & 5 & 7 \\
% %%     2 & 1 & 5 & 7 \\
% %%     2 & 1 & 5 & 7 
% %%   \end{bmatrix}.$$
% %% Here, we have $p=3, q=4, s=0$ and $n=2$. Then, 
% %% the quantity $c$ is $c=E_2(2,1,5,7) = 2\cdot1+2\cdot5+2\cdot7+1\cdot5+1\cdot7+5\cdot7 = {73}$,
% %% whereas $c'=6 \cdot 7^2=294.$ On the other hand, if we 
% %% take $\mF$ with degree profile
% %% $$ \begin{bmatrix}
% %%     2 & 2 & 2 & 2 \\
% %%     1 & 1 & 1 & 1 \\
% %%     5 & 5 & 5 & 5 
% %%   \end{bmatrix},$$
% %% with the same values of $p,q,s,n$, we get $c=6 \cdot 7^2=294$ and
% %% $c'=S_2(2,1,5) = 2^2+2\cdot 1 + 2\cdot 5 + 1^2 + 1 \cdot 5 + 5^2 =
% %% {47}$.

% \begin{example}
%   In our example, we have no polynomials $\mG$, so $s=0$. The column degrees of
%   $\mF$ are $(\cdeg(\mF,1),\cdeg(\mF,2),\cdeg(\mF,3))=(2,2,2)$, whereas its
%   row degrees are $(\rdeg(\mF,1),\rdeg(\mF,2))=(1,2)$. 

%   The column degree bound is $c=E_2(2,2,2) = 2^2 + 2^2 +
%   2^2 =12$, the row degree bound is $c'=S_2(1,2) = 1^2 + 1\cdot 2 +
%   2^2 = 7$. The latter is sharp.
% \end{example}
% For systems coming from optimization, where $\mF$ is a Jacobian
% matrix, we are in a situation similar to our example, where the $i$th
% row degree of $\mF$ is simply the degree of the corresponding
% equation, minus one.

% Although results in a similar vein have already been published, we are
% not aware of previous statements as above, with no assumption on the
% dimension of $V_p(\mF,\mG)$, and that take into account multiplicities
% as is done in Theorem~\ref{theo:1}.

% Pioneering work of Giambelli-Thom-Porteous (see e.g. \cite{FP06} or
% \cite{Fu92}) already established similar bounds under regularity
% assumptions (when $V(\mG)$ is smooth and/or $V_p(\mF, \mG)$ has the
% expected codimension). Previous work by Miller and
% Sturmfels~\cite[Chapter~15]{MiSt04} proved very general results on the
% multi-degrees of determinantal ideals built from matrices with
% indeterminate entries (in which case we have $s=0$, but the assumption
% $n=q-p+1$ does not hold); in particular, they obtain analogues (and
% generalizations) of the result in Theorem~\ref{theo:1} in that
% context.

% Nie and Ranestad proved in~\cite{NieRan09} that the bounds in
% Theorem~\ref{theo:1} are tight for two families of polynomials
% (in a similar context where the polynomials are homogeneous in
% $n+1$ variables):
% \begin{itemize}
% \item when entries of $\mF$ are generic and homogeneous, and
%  such that $\deg(f_{i,j}) = \cdeg(\mF,j)$ for all $i,j$, the ideal
%  generated by the $p$-minors of $\mF$ has degree $E_{n}(\cdeg(\mF,1), \ldots, \cdeg(\mF,q))$;
% \item when entries of $\mF$ are  generic and homogeneous, and
%   such that $\deg(f_{i,j}) = \rdeg(\mF,i)$ for all $i,j$, the
%   ideal generated by the $p$-minors of $\mF$
%  has degree $S_{n}(\rdeg(\mF,1), \ldots, \rdeg(\mF,p))$.
% \end{itemize}
% From this, they deduce that the degree of the ideal generated by the
% $p$-minors of $\mF$ and $ g_1,\dots,g_s $ is at most \sloppy
% $\deg(g_1) \cdots \deg(g_s) S_{n-s}(\rdeg(\mF,1), \ldots,
% \rdeg(\mF,p))$, for systems coming from optimization, assuming that
% this ideal has dimension zero. In this context, Spaenlehauer also gave
% in~\cite{Spa14} an explicit expression for the Hilbert function of the
% ideal above, for a generic input.

% \medskip

% Our second result gives bounds on the cost of computing a
% zero-dimensional parametrization of the isolated solutions of
% $\VpFG{p}{\mF}{\mG}$. Our
% algorithms take as input a \emph{straight-line program} (that is, a
% sequence of elementary operations $+, -, \times$) that computes the
% entries of $\mF$ and $\mG$ from the input variables $X_1,\dots,X_n$; the
% \emph{length $\sigma$} of the input is the number of operations it
% performs. This assumption is not restrictive, since any matrix $\mF$
% and polynomials $\mG$ can be computed by a straight-line program (a
% naive solution would consist in computing and adding all monomials in
% $\mF$ and $\mG$).

% \begin{theorem}\label{theo:2}
%   Suppose that matrix $\mF \in \KK[X_1,\dots,X_n]^{p \times q}$ and
%   polynomials $\mG=(g_1,\dots,g_s)$ in $\KK[X_1,\dots,X_n]$ are given by
%   a straight-line program of length $\sigma$. Assume that
%   $\deg(g_1),\dots,\deg(g_s)$, as well as
%   $\cdeg(\mF,1), \ldots, \cdeg(\mF,q)$ and
%   $\rdeg(\mF,1), \ldots, \rdeg(\mF,p)$ are all at least equal to $1$.

%   Then, there exist randomized algorithms that solve
%   Problem~\eqref{problem2} in either
%    $$\softO\left (
%      {q \choose p} c(e+c^5 )\big(\sigma + q \delta + \gamma  \big )
%    \right)$$
%   operations in $\KK$, with
%   \begin{align*}
%     c&=\deg(g_1)\cdots\deg(g_s)\ E_{n-s}(\cdeg(\mF,1), \ldots, \cdeg(\mF,q))\\
%     e&=(\deg(g_1)+1)\cdots(\deg(g_s)+1)\ E_{n-s}(\cdeg(\mF,1)+1, \ldots, \cdeg(\mF,q)+1),\\
%     \gamma&= \max(\deg(g_i), 1\leq i \leq s)\\
%     \delta &= \max(\cdeg(\mF,i), 1\leq i \leq q)
%   \end{align*}
%   or 
%    $$\softO\left (
%      {q \choose p} c'(e'+{c'}^5 )\big(\sigma + p \alpha  +\gamma \big )
%    \right)$$
%   operations in $\KK$, with 
% \begin{align*}
%   c'&=\deg(g_1)\cdots\deg(g_s)\ S_{n-s}(\rdeg(\mF,1), \ldots, \rdeg(\mF,p))\\
%   e'&=(\deg(g_1)+1)\cdots(\deg(g_s)+1)\ S_{n-s}(\rdeg(\mF,1)+1, \ldots, \rdeg(\mF,p)+1),\\
%     \gamma&= \max(\deg(g_i), 1\leq i \leq s)\\
%     \alpha &= \max(\rdeg(\mF,j), 1\leq j \leq p).
% \end{align*}
% \end{theorem}
% \textcolor{brown}{The assumption that all degrees are at least $1$ is not a restriction.
% If $\deg(g_i)=0$ for some $i$, $g_i$ is a constant, so either the
% system is inconsistent (if $g_i \ne 0$) or $g_i$ can be
% discarded. Similarly, if say $\cdeg(\mF,i)=0$, the $i$th column of
% $\mF$ consists of constants; after applying linear combinations with
% coefficients in $\KK$ to the rows of $\mF$, we may assume that all
% entries in the $i$th column, except at most one, are non-zero without
% changing the column degrees. The $i$th column of $\mF$ (and the row of
% the non-zero entry, if there is one) can then be discarded.}

% Remark further that in the common situation where all degrees
% $\deg(g_i)$, $\rdeg(\mF,i)$ and $\cdeg(\mF,j)$ involved in the
% formulas above are at least equal to $2$, we have the inequalities $e
% \le c^2$, $e' \le {c'}{}^2$ and $\binom{q}{p}\leq c$,
% $\binom{q}{p}\leq c'$. As a result, the runtimes are {\em polynomial}
% in $c,\sigma$ and $c',\sigma$: they respectively become
% $\softO (c^8 \sigma)$ and $\softO ({c'}^8 \sigma)$.  This is to be
% compared with Theorem~\ref{theo:1}, which shows that $\min(c,c')$ is a
% natural upper bound for the output size of such~algorithms.

% For solving Problem~\eqref{problem3}, one obtains slightly better
% complexity estimates. 

% \begin{theorem}\label{theo:3}
%   Suppose that the matrix $\mF \in \KK[X_1,\dots,X_n]^{p \times q}$
%   and polynomials $\mG=(g_1,\dots,g_s)$ in $\KK[X_1,\dots,X_n]$ are
%   given by a straight-line program of length $\sigma$. Assume that
%   $\deg(g_1),\dots,\deg(g_s)$, as well as
%   $\cdeg(\mF,1), \ldots, \cdeg(\mF,q)$ and
%   $\rdeg(\mF,1), \ldots, \rdeg(\mF,p)$ are all at least equal to $1$.

%   Then, there exist randomized algorithms that solve
%   Problem~\eqref{problem3} in either
%    $$\softO\left (
%      {q \choose p} ce\big(\sigma + q \delta + \gamma  \big )
%    \right)$$
% or 
%    $$\softO\left (
%      {q \choose p} c'e'\big(\sigma + p \alpha  +\gamma \big )
%    \right)$$
%   operations in $\KK$, 
%   all notations being as in Theorem~\ref{theo:3}.
% \end{theorem}
% As above, in the common situation where all degrees involved are at
% least $2$, the runtimes are {\it polynomial} in $c, \sigma$ and
% $c',\sigma'$; precisely, they respectively become $\softO (c^5 \sigma)$ and $\softO
% ({c'}^5 \sigma)$.


% The probabilistic aspects are as follows: at several steps, the
% algorithms on which Theorems~\ref{theo:2} and~\ref{theo:3} rely will
% draw elements from the base field at random. In all cases, there
% exists an algebraic hypersurface $\cal H$ of the parameter space such
% that success is guaranteed for all choices of parameters not
% in~$\cal H$.


% %% The number ${q \choose p}$ is the number of elements in the
% %% determinantal system of $\mF$. In several cases, we can improve the
% %% algorithm and replace this by the number $q$ of columns of $\mF$, for
% %% instance, when all isolated solutions of $I_\mF$ are known to have
% %% multiplicity one.

% As already said, our algorithms are based on a {\em symbolic homotopy
%   continuation}. Following early work in the 1930's, such
% as~\cite{Lahaye34}, homotopy continuation algorithms have become a
% foundational tools for numerical algorithms; see for
% instance~\cite{AlGe03} for an extensive list of references.  We
% mention in particular Shub and Smale's work on the complexity of these
% techniques, starting from~\cite{ShSm93}, or work by Morgan, Sommese,
% Wampler (as summarized, for instance, in~\cite{BertiniBook,SoWa05}),
% with an emphasis on the underlying algebraic geometry. In this
% context, dedicated numerical homotopy algorithms have also been
% developed to take into account sparsity in polynomial
% systems~\cite{Ver94,Ver09,AdVe13}.

% By contrast, the usage of homotopy methods in symbolic contexts is
% more recent, even though some early results, such as Bernstein's proof
% of the so-called BKK theorem, already involve Puiseux series
% manipulations~\cite{Bernstein75}. References such
% as~\cite{HeKrPuSaWa99,BoMaWaWa04} deal with systems with no particular
% structure, or systems with no zeros at infinity~\cite{PaSa04}.
% Further work extended this idea to sparse systems (in the polyhedral
% sense)~\cite{JeMaSoWa09,HeJeSa10,HeJeSa13,HeJeSa14} and
% multihomogeneous systems~\cite{HeJeSaSo02,SaSc16}.  In~\cite{SaSc16},
% these techniques are used to solve Problem~\eqref{problem3}, but the
% complexity estimates obtained there depend on multi-homogeneous
% B\'ezout bounds involving the maxima of $\rdeg(\mF, 1), \ldots,
% \rdeg(\mF, p)$ or $\cdeg(\mF,1), \ldots, \cdeg(\mF, q)$.

% Most algorithms in the previous references have in common that they
% solve {\em square} systems, that is, systems with as many equations as
% unknowns; extensions of these methods can deal with systems of
% positive dimension by essentially using variants of the algorithm for
% square systems.  One notable exception is given in \cite{SVV10}, where
% dedicated homotopy algorithms are given to solve Schubert problems
% which consist in determining linear spaces of prescribed dimension
% which meet a set of fixed linear subspaces in specified
% dimensions; such problems are formulated with rank
% conditions on some special matrices~\cite{LDSVV18}. These
% algorithms strongly exploit and are dedicated to the structure of the
% Schubert problem through the Littlewood Richardson rule and an
% associated combinatorial construction. Hence, as far as we know, they
% cannot be used to solve determinantal systems of equations expressing
% that a given matrix with polynomial entries is rank deficient. 

% One of the contributions in this paper is to deal with determinantal
% systems of equations, which are in essence over-determined; this is
% made possible by the algebraic properties of determinantal ideals.

% It is well known that Gr\"obner bases behave rather well on
% over-determined systems. Starting from the determination of the
% Hilbert function of a determinantal ring due to Conca and
% Herzog~\cite{CH94}, complexity estimates are given in
% \cite{FSS13,FSS12} for computing Gr\"obner bases of ideals generated
% by either $M_r(\mF)$ when $r\leq p\leq q$, or
% $M_{p}(\mF),g_1,\dots,g_s$, (for inputs coming from optimization
% problems), but under some genericity assumptions on the entries of
% $\mF$ or $\mG$; the input polynomials are also assumed to all have the
% same degree.  This series of works culminated with the result obtained
% by Spaenlehauer in \cite{Spa14}, where he removes this latter degree
% assumption and provides sharp complexity statements, still under
% genericity~assumptions.

% Systems encoding rank defects in polynomial matrices have also been
% studied in the scope of the so-called geometric resolution algorithm
% in \cite{BaGiHeLeMaSo15}, with a slight generalization in
% \cite{SaSp16}. The algorithms in these references work for generic
% inputs and solve only our second problem, computing simple solutions
% (isolated solutions which are not simple are not considered in that
% line of work). The cost of these algorithms is quadratic in certain
% geometric quantities (the degree of algebraic sets defined by
% subsystems of the determinantal equations we are dealing with); this
% is to be compared with the runtimes in Theorem~\ref{theo:3}, where the
% main contributions are the products ${q \choose p} c e$, respectively
% ${q \choose p} c' e'$, and where $ce$, resp.\ $c'e'$, are also of a
% geometric nature.  In cases where the results
% of~\cite{BaGiHeLeMaSo15,SaSp16} apply, further work is needed to
% compare the degrees involved in these complexity estimates with ours, and the
% resulting runtimes.

% \medskip In the following paragraphs, we describe our results in more
% detail, and introduce notation in use in all the paper. We start from
% polynomials $\mG=(g_1,\dots,g_s)$ in $\KK[\bX]=\KK[X_1,\dots,X_n]$ and
% polynomial matrix $\mF \in \KK[\bX]^{p \times q}$; the equations
% $\bC=(c_1,\dots,c_{s},\dots,c_m)$ that we want to solve are defined as
% follows: $(c_1,\dots,c_{s})=(g_1,\dots,g_s)$, and
% $(c_{s+1},\dots,c_{m})$ are the $p$-minors of $\mF$.

% As a preliminary, we will need an algorithm which takes as input
% polynomials $\bC$ and a point $\bx$ in the zero-set of $\bC$, and
% which decides whether $\bx$ is an isolated points of $V(\bC)$ (this
% will be used to solve Problem~\eqref{problem2}).  Without any other
% information, this decision problem is difficult to solve in a good
% complexity. However, when a bound $\mu$ is known on the multiplicity
% of $\bx$ as a root of $\bC$, it becomes possible to solve this problem
% in time polynomial in the number of equations $m$, the number of
% variables $n$, the bound $\mu$, and the complexity of evaluation
% $\sigma$ of $\bC$. This is detailed in Section~\ref{sec:isolated},
% where we explain how to modify an algorithm by
% Mourrain~\cite{Mourrain97} and adapt it to our context.

% In order to compute the isolated points, or the simple points, of
% $V(\bC)$, we work with a deformation of these equations.  We let $T$ be a
% new variable, and we define 
% polynomials $\bV=(v_1,\dots,v_s)$ of the form
% \begin{equation}\label{eqdef:bV}
% \bV = (1-T) \cdot \bM + T \cdot \mG,  
% \end{equation}
% that connect certain polynomials $\bM=(m_1,\dots,m_s)$ to the target
% system $\mG$, together with 
% the matrix
% \begin{equation}\label{eqdef:bU}
% \bU = (1-T)\cdot \bL + T \cdot \mF \in \KK[T, X_1,\dots,X_n]^{p \times q}  
% \end{equation}
% that connects a suitable \emph{start matrix} $\bL$ to the target matrix $\mF$.
% \begin{itemize}
% \item The {\em start system} $\bA=(a_1,\dots,a_m)$ will be defined by
%   taking $(a_1,\dots,a_s) = (m_1,\dots,m_s)$, and by letting
%   $(a_{s+1},\dots,a_m)$ be the $p$-minors of $\bL$; these polynomials 
%   are in $\KK[X_1,\dots,X_n]$. 
% \item The parametric system $\bB=(b_1,\dots,b_m)$ will be defined by
%   taking $(b_1,\dots,b_s) = (v_1,\dots,v_s)$, and by letting
%   $(b_{s+1},\dots,b_m)$ be the $p$-minors of $\bU$; these polynomials 
%   are in $\KK[T,X_1,\dots,X_n]$. 
% \end{itemize}
% In particular, setting $T=0$ in $\bB$ gives us $\bA$, and 
% setting $T=1$ in it recovers $\bC$.

% In Sections~\ref{sec:check} and~\ref{sec:homotopy}, we prove a few
% properties of the ideal generated by $\bB$, independently of the
% choices of $\bL$ and $\bM$.  Then, in Section~\ref{sec:homotalgo}, we
% give symbolic homotopy algorithms which take as input the sequence of
% polynomials $\bB$, together with a description of $V(\bA)$ (under
% certain regularity assumptions), and computes a zero-dimensional
% parametrization of either the isolated solutions, or the simple
% solutions of $\bC$. This is done by lifting the points of $V(\bA)$
% (that correspond to $T=0$) into a curve $\cal C$ parametrized by
% $T$. The isolated points of $V(\bC)$ all belong to the fiber of $\cal
% C$ above $T=1$, but some points in this fiber can actually lie in
% positive dimensional components of $V(\bC)$; the algorithm of
% Section~\ref{sec:isolated} will filter out such points. To find simple
% points, the procedure will be slightly simpler.

% To give concrete algorithms, we will have to specify how to define
% polynomials $\bM$ and matrix $\bL$, and how to find the solutions of 
% $\bA=0$.
% The main difficulty lies in the definition of a matrix
% $\bL$ that will respect either the column-degree or the row-degree of
% $\mF$, while satisfying all assumptions needed for the algorithm of
% Section~\ref{sec:homotalgo} and allowing us to solve
% the resulting system $\bA=0$ easily.
%   The column-degree case is treated in
% Section~\ref{sec:columndegree} in a rather straightforward way,
% whereas the row-degree case is more delicate, and is treated in
% Sections~\ref{sec:prel-row} and~\ref{sec:rowdegree}. The proofs of
% some properties needed in the latter sections are postponed to the
% appendix of the paper.


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
